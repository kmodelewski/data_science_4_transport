# Analityka danych w transporcie


## Program szkolenia

## Harmonogram szkolenia

### Dzien 1
1. Analityka Self Service 09:00 - 11:00
    - Definicja i zastosowanie Lakehouse 
    - Architektura Medalionowa 
    - Unity Catalog
    - Otwarty Format Delta i jego zastosowanie w analityce danych
    - [Lab 1] Właściwości formatu Delta
2. Wprowadzenie do platformy Databricks 11:15 - 14:00
   - Architektura (Data Plane i Control Plane)
   - [Lab 2] Praca z notatnikami
   - Obiekty Databricks
     - Klastry obliczeniowe (Compute)
     - Przepływy danych (Workflows)
     - Zadania (Jobs)
     - Notatniki (Notebooks)
     - Raporty (Dashboard)
   - Otoczenie Databricks:
     - MS Azure (Blob Storage, Key Vault)
     - [Lab 3] Pierwszy projekt analityczny
3. Wprowadzenie do analizy danych w SQL 14:15 - 16:00
  - Wprowadzenie do SQL
    - Group by
    - Case When
    - Wyrażenia CTE
    - [Lab 4] Przetwarzanie plików JSON w SQL z IoT.

### Dzien 2
1. Wprowadzenie analizy danych w języku Python 9:00 - 12:00
  - [Lab 1] Python - typy danych
  - [Lab 2] Python - pobieranie rozkładu jazdy przez API
  - Wprowadzenie do bilbioteki Pandas

2. Analiza danych 11:15 - 15:00
    - [Lab 2] Analiza danych z systemu wideodetekcji (*.csv)
    - [Lab 2] Analiza danych z transportu publicznego (*.json/*.gtfs)

3. Przetwarzenie równoległe w Apache Spark 15:00 - 16:00



### Dzien 3
1. Podstawowe transformacje w Pyspark
   - filtrowanie
   - grupowanie
   - praca z różnymi typami plików
2. [lab] Analiza danych w Pyspark
3. Przejścia pomiędzy SQL, Pandas i Pyspark
3. Optymalizacja zapisu danych
4. [lab] Projekt końcowy




## Prowadzacy

Krzysztof Modelewski jest absolwentem Wydziału Transportu Politechniki Warszawskiej o specjalności Telematyka Transportu. Uczestnik szkoleń
w zakresie Inteligentnych Systemów Transportowych, m.in. projektowania sygnalizacji świetlnych. Autor książki “Inteligentny Transport”. Kierownik
budowy „Krajowego Punktu Dostępowego do informacji o warunkach ruchu” https://kpd.gddkia.gov.pl/ . Posiadacz m.in. certyfikatów Project Management Professional 
i OMG-Certified Expert in BPM (Business Process Management). Obecnie Senior Data Engineer zajmujący się zaawansowaną analityką danych z wykorzystaniem 
technologii chmurowych m.in. Databricks, Microsoft Fabric i Snowflake.


   