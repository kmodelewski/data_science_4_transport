# Analityka danych w transporcie


## Program szkolenia

## Harmonogram szkolenia

### Dzien 1
1. **Analityka Self Service 09:00 - 11:00**
    - Definicja i zastosowanie Lakehouse 
    - Architektura Medalionowa 
    - Data governance
    - Otwartość danych
    - Przegląd platform Databricks, Snowflake, Microsoft Fabric
    - Otwarty Format Delta i jego zastosowanie w analityce danych
    - Właściwości formatu Delta
    - [Lab 1] Standard Delta Lake
2. **[Lab 2] Wprowadzenie do platformy Databricks - KPD GDDKiA 11:15 - 14:00**
    - Infrastruktura jako kod (terraform)
    - Architektura (Data Plane i Control Plane)
    - Praca z notatnikami
    - Obiekty Databricks
        - Klastry obliczeniowe (Compute)
        - Przepływy danych (Workflows)
        - Zadania (Jobs i Pipelines)
        - Notatniki (Notebooks)
        - Raporty (Dashboard)
   - **Otoczenie Databricks:**
     - MS Azure (Blob Storage, Key Vault)
     - Amazon AWS (S3)
     - Pobranie archiwalnych danych KPD GDDKiA do Databricks
3. **Wprowadzenie do analizy danych w SQL 14:15 - 16:00**
     - Group by
     - Case When
     - Common Table Expressions (CTE)
     - Joins
     - Window Functions
     - [Lab 4] Przetwarzanie plików z KPD GDDKiA w SQL.

### Dzien 2
1. **Wprowadzenie analizy danych w języku Python 9:00 - 12:00**
       - Wprowadzenie do python 
         - typy danych
         - klasy i funkcje
       - Przetwarzanie równoległe w Spark
           - architektura Spark
           - wyzwania przetwarzania w Big Data
2. **Wprowadzenie do biblioteki Pandas i Pyspark 13:00 - 16:00**
     - podstawowe transformacje w Pyspark
     - praca z różnymi typami plików
     - przejście pomiędzy SQL, Pandas i Pyspark
     - Optymalizacja zapisu danych

    
### Dzien 3
1. **Analiza danych w transporcie publicznym (*.json)**
    - zebranie danych z API (otwarte publicznie dane)
    - utworzenie modelu danych
    - utworzenie przepływu danych
2. **Wizualizacja danych**
3. **Udostępnianie danych (Delta Sharing, Clean Room)**


## Prowadzacy

Krzysztof Modelewski jest absolwentem Wydziału Transportu Politechniki Warszawskiej o specjalności Telematyka Transportu. Uczestnik szkoleń
w zakresie Inteligentnych Systemów Transportowych, m.in. projektowania sygnalizacji świetlnych. Autor książki “Inteligentny Transport”. Kierownik
budowy „Krajowego Punktu Dostępowego do informacji o warunkach ruchu” https://kpd.gddkia.gov.pl/ . Posiadacz m.in. certyfikatów Project Management Professional 
i OMG-Certified Expert in BPM (Business Process Management). Obecnie Senior Data Engineer zajmujący się zaawansowaną analityką danych z wykorzystaniem 
technologii chmurowych m.in. Databricks, Microsoft Fabric i Snowflake.




   